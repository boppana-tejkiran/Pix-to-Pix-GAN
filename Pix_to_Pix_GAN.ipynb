{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FXmu_bLQKssuAjflRAYzopm67PJ-umil",
      "authorship_tag": "ABX9TyPMsoVq4LG3IxTPDGc/doLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boppana-tejkiran/Pix-to-Pix-GAN/blob/main/Pix_to_Pix_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ki3FpPVHzcK",
        "outputId": "50ff6321-6e97-4698-fab4-7aa41aefff22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4YQpsfh3DqSu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator Network"
      ],
      "metadata": {
        "id": "QleJCI8iLDn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride = 2):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, 4, stride, bias = False, padding_mode = 'reflect'),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    self.initial = nn.Sequential(\n",
        "        nn.Conv2d(in_channels*2, features[0], kernel_size = 4, stride = 2, padding = 1, padding_mode = 'reflect'),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    layers = []\n",
        "    in_channels = features[0]\n",
        "    for feature in features[1:]:\n",
        "      layers.append(\n",
        "          CNNBlock(in_channels, feature, stride = 1 if feature == features[-1] else 2)\n",
        "      )\n",
        "      in_channels = feature\n",
        "    \n",
        "    layers.append(\n",
        "        nn.Conv2d(in_channels, 1, kernel_size = 4, stride =1, padding=1, padding_mode = 'reflect')\n",
        "    )\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x = torch.cat([x,y], dim =1)\n",
        "    x = self.initial(x)\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "pEL07g7LIDVy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((1, 3, 256, 256))\n",
        "  y = torch.randn((1, 3, 256, 256))\n",
        "  model = Discriminator()\n",
        "  preds = model(x, y)\n",
        "  print(preds.shape)"
      ],
      "metadata": {
        "id": "mVa5leKlJfip"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26ZCmrNTKKfK",
        "outputId": "cc3ea05c-3e0f-4388-ea7a-b698862efe11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 26, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator Network"
      ],
      "metadata": {
        "id": "L7Aho0H6LKVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, down = True, act = 'relu', use_dropout = False):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias = False, padding_mode = 'reflect')\n",
        "        if down\n",
        "        else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    self.use_dropout = use_dropout\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return self.dropout(x) if self.use_dropout else x\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels = 3, features = 64):\n",
        "    super().__init__()\n",
        "    self.initial_down = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode = 'reflect'),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    self.down1 = Block(features, features*2, down = True, act = 'leaky', use_dropout=False) #128\n",
        "    self.down2 = Block(features*2, features*4, down = True, act = 'leaky', use_dropout=False) #64\n",
        "    self.down3 = Block(features*4, features*8, down = True, act = 'leaky', use_dropout=False) #32\n",
        "    self.down4 = Block(features*8, features*8, down = True, act = 'leaky', use_dropout=False) #16\n",
        "    self.down5 = Block(features*8, features*8, down = True, act = 'leaky', use_dropout=False) # 4\n",
        "    self.down6 = Block(features*8, features*8, down = True, act = 'leaky', use_dropout=False) # 2\n",
        "    self.bottleneck = nn.Sequential(\n",
        "        nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode = \"reflect\"), nn.ReLU() # 1 x 1\n",
        "    )\n",
        "    self.up1  = Block(features*8, features*8, down = False, act = 'relu', use_dropout = True)\n",
        "    self.up2  = Block(features*8*2, features*8, down = False, act = 'relu', use_dropout = True)\n",
        "    self.up3  = Block(features*8*2, features*8, down = False, act = 'relu', use_dropout = True)\n",
        "    self.up4  = Block(features*8*2, features*8, down = False, act = 'relu', use_dropout = True)\n",
        "    self.up5  = Block(features*8*2, features*4, down = False, act = 'relu', use_dropout = True)\n",
        "    self.up6  = Block(features*4*2, features*2, down = False, act = 'relu', use_dropout = True)\n",
        "    self.up7  = Block(features*2*2, features, down = False, act = 'relu', use_dropout = True)\n",
        "\n",
        "    self.final_up = nn.Sequential(\n",
        "        nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride = 2, padding = 1),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    d1 = self.initial_down(x)\n",
        "    d2 = self.down1(d1)\n",
        "    d3 = self.down2(d2)\n",
        "    d4 = self.down3(d3)\n",
        "    d5 = self.down4(d4)\n",
        "    d6 = self.down5(d5)\n",
        "    d7 = self.down6(d6)\n",
        "\n",
        "    bottleneck = self.bottleneck(d7)\n",
        "\n",
        "    up1 = self.up1(bottleneck)\n",
        "    up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "    up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "    up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "    up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "    up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "    up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "\n",
        "    return self.final_up(torch.cat([up7, d1], 1))      "
      ],
      "metadata": {
        "id": "8dZKliRMKLzQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  x = torch.randn((1, 3, 256, 256))\n",
        "  model = Generator()\n",
        "  preds = model(x)\n",
        "  print(preds.shape)"
      ],
      "metadata": {
        "id": "ZWH6eQrKMefF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdy_WDQYQJEx",
        "outputId": "56398d05-75f9-422b-f7ef-313a6d8650c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 2e-4\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "img_size = 256\n",
        "channels_ing = 100\n",
        "l1_lambda = 100\n",
        "num_epochs = 500\n",
        "load_model = False\n",
        "save_model = True\n",
        "checkpoint_disc = \"disc.pth.tar\"\n",
        "checkpoint_gen = \"gen_pth.tar\"\n",
        "\n",
        "both_transform = A.Compose(\n",
        "    [A.Resize(width=256, height=256), A.HorizontalFlip(p=0.5)], additional_targets = {\"image0\": \"image\"}\n",
        ")\n",
        "\n",
        "transform_only_input = A.Compose(\n",
        "    [A.ColorJitter(p=0.1),\n",
        "     A.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5], max_pixel_value = 255.0),\n",
        "     ToTensorV2()]\n",
        ")\n",
        "\n",
        "transform_only_mask = A.Compose(\n",
        "     [A.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5], max_pixel_value = 255.0),\n",
        "     ToTensorV2()]\n",
        ")"
      ],
      "metadata": {
        "id": "sAK-s-thiO2l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset"
      ],
      "metadata": {
        "id": "l0dvkdbTh-gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dir_path):\n",
        "    self.root_dir = dir_path\n",
        "    self.list_files = os.listdir(self.root_dir)\n",
        "    # print(self.list_files)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.list_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_file = self.list_files[index]\n",
        "    img_path = os.path.join(self.root_dir, img_file)\n",
        "    image = np.array(Image.open(img_path))\n",
        "    input_image= image[:, :600, :]\n",
        "    target_image = image[:, 600:, :]\n",
        "\n",
        "    augmentations = both_transform(image = input_image, image0 = target_image)\n",
        "    input_image, target_image = augmentations['image'], augmentations['image0']\n",
        "\n",
        "    input_image = transform_only_input(image = input_image)['image']\n",
        "    target_image = transform_only_input(image = target_image)['image']\n",
        "\n",
        "    return input_image, target_image"
      ],
      "metadata": {
        "id": "a7TIocjtQPJ5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save and Load Check Points"
      ],
      "metadata": {
        "id": "q0qanSIih5PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "def save_some_examples(gen, val_loader, epoch, folder):\n",
        "  x, y = next(iter(val_loader))\n",
        "  x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "  gen.eval()\n",
        "  with torch.no_grad():\n",
        "    y_fake = gen(x)\n",
        "    y_fake = y_fake * 0.5 + 0.5 # remove normalization\n",
        "    save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
        "    save_image(x * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "    if epoch == 1:\n",
        "      save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
        "  gen.train()\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename = \"mychcekpoint.pth.tar\"):\n",
        "  print(\"Saving checkpoint..\")\n",
        "  checkpoint = {\n",
        "      \"state_dict\" : model.state_dict(),\n",
        "      \"optimizer\" : optimizer.state_dict()\n",
        "  }\n",
        "  torch.save(checkpoint, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "  print(\"Loading checkpoint..\")\n",
        "  checkpoint = torch.load(checkpoint_file, map_location= DEVICE)\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "vNv9rhW6h4nO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "V7Fx8F_3nBUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(disc, gen, loader, opt_disc, opt_gen, l1, bce, g_scalar, d_scalar):\n",
        "  loop = tqdm(loader, leave = True)\n",
        "\n",
        "  for idx, (x, y) in enumerate(loop):\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "    # Train Discriminator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      y_fake = gen(x)\n",
        "      d_real = disc(x, y)\n",
        "      d_fake = disc(x, y_fake.detach())\n",
        "\n",
        "      d_real_loss = bce(d_real, torch.ones_like(d_real))\n",
        "      d_fake_loss = bce(d_fake, torch.zeros_like(d_fake))\n",
        "      d_loss = (d_real_loss + d_fake_loss)/2\n",
        "    \n",
        "    disc.zero_grad()\n",
        "    d_scalar.scale(d_loss).backward()\n",
        "    d_scalar.step(opt_disc)\n",
        "    d_scalar.update()\n",
        "\n",
        "    # Train Generator\n",
        "    with torch.cuda.amp.autocast():\n",
        "      d_fake = disc(x, y_fake)\n",
        "      g_fake_loss = bce(d_fake, torch.ones_like(d_fake))\n",
        "      L1 = l1(y_fake, y) * l1_lambda\n",
        "      g_loss = g_fake_loss + L1\n",
        "    \n",
        "    opt_gen.zero_grad()\n",
        "    g_scalar.scale(g_loss).backward()\n",
        "    g_scalar.step(opt_gen)\n",
        "    g_scalar.update()\n",
        "\n",
        "def main():\n",
        "  disc = Discriminator(in_channels=3).to(DEVICE)\n",
        "  gen = Generator(in_channels =3).to(DEVICE)\n",
        "  opt_disc = optim.Adam(disc.parameters(), lr = lr, betas = (0.5, 0.999))\n",
        "  opt_gen = optim.Adam(gen.parameters(), lr = lr, betas = (0.5, 0.999))\n",
        "  BCE = nn.BCEWithLogitsLoss()\n",
        "  L1_Loss = nn.L1Loss()\n",
        "\n",
        "  if load_model:\n",
        "    load_checkpoint(checkpoint_gen, gen, opt_gen, lr)\n",
        "    load_checkpoint(checkpoint_disc, disc, opt_disc, lr)\n",
        "\n",
        "  train_dataset = CustomDataset(dir_path=\"/content/drive/MyDrive/data/maps/train\")\n",
        "  train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = num_workers)\n",
        "  g_scalar = torch.cuda.amp.GradScaler()\n",
        "  d_scalar = torch.cuda.amp.GradScaler()\n",
        "  val_dataset = CustomDataset(dir_path = \"/content/drive/MyDrive/data/maps/val\")\n",
        "  val_loader = DataLoader(val_dataset, batch_size = 8, shuffle = False)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    train(disc, gen, train_loader, opt_disc, opt_gen, L1_Loss, BCE, g_scalar, d_scalar)\n",
        "\n",
        "    if save_model and epoch % 5 == 0:\n",
        "      save_checkpoint(gen, opt_gen, filename = checkpoint_gen)\n",
        "      save_checkpoint(disc, opt_disc, filename = checkpoint_disc)\n",
        "\n",
        "    save_some_examples(gen, val_loader, epoch, folder = '/content/drive/MyDrive/evaluation')"
      ],
      "metadata": {
        "id": "ZXhCRE7-m-zJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts_GGrcGDnQu",
        "outputId": "63e5a9cc-d3ea-46a5-a5b6-53c1da600061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:47<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint..\n",
            "Saving checkpoint..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:19<00:00,  3.53it/s]\n",
            "100%|██████████| 70/70 [00:19<00:00,  3.54it/s]\n",
            " 44%|████▍     | 31/70 [00:09<00:11,  3.46it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PV12Dq-WQbQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}